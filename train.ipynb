{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "from utils.dataset import DrawingsDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train images: 40000\n",
      "Test images: 10000\n",
      "Training:   0%|          | 1/313 [00:00<00:51,  6.08it/s]\n",
      "EPOCH: 1\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 169.10it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 389.19it/s]\n",
      "Training:   4%|▍         | 13/313 [00:00<00:02, 126.81it/s]Test loss: 1.3090746100944808\n",
      "\n",
      "new best accuracy: 0.5392\n",
      "\n",
      "EPOCH: 2\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 195.37it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 394.70it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 196.57it/s]Test loss: 0.5216582715511322\n",
      "\n",
      "new best accuracy: 0.8449\n",
      "\n",
      "EPOCH: 3\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 202.81it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 423.96it/s]\n",
      "Training:   7%|▋         | 22/313 [00:00<00:01, 212.83it/s]Test loss: 0.42946801796744144\n",
      "\n",
      "new best accuracy: 0.8695\n",
      "\n",
      "EPOCH: 4\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 216.81it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 407.38it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 194.97it/s]Test loss: 0.37924542853349374\n",
      "\n",
      "new best accuracy: 0.8907\n",
      "\n",
      "EPOCH: 5\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 193.00it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 452.47it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 197.55it/s]Test loss: 0.3482901155948639\n",
      "\n",
      "new best accuracy: 0.8972\n",
      "\n",
      "EPOCH: 6\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 200.54it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 375.49it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 199.99it/s]Test loss: 0.329087269645703\n",
      "\n",
      "new best accuracy: 0.9027\n",
      "\n",
      "EPOCH: 7\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 211.39it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 417.44it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 197.11it/s]Test loss: 0.3175371760808969\n",
      "\n",
      "new best accuracy: 0.9077\n",
      "\n",
      "EPOCH: 8\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 208.20it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 448.94it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 202.70it/s]Test loss: 0.32793593255779413\n",
      "\n",
      "EPOCH: 9\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 211.70it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 444.99it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 203.48it/s]Test loss: 0.2957564098171041\n",
      "\n",
      "new best accuracy: 0.9121\n",
      "\n",
      "EPOCH: 10\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 209.92it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 463.47it/s]\n",
      "Training:   6%|▌         | 18/313 [00:00<00:01, 177.63it/s]Test loss: 0.3073267004912413\n",
      "\n",
      "EPOCH: 11\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 200.95it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 426.27it/s]\n",
      "Training:   7%|▋         | 22/313 [00:00<00:01, 211.74it/s]Test loss: 0.2968470209007022\n",
      "\n",
      "EPOCH: 12\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 211.15it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 450.13it/s]\n",
      "Training:   7%|▋         | 22/313 [00:00<00:01, 213.70it/s]Test loss: 0.2822812967285325\n",
      "\n",
      "EPOCH: 13\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 212.72it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 443.29it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 193.04it/s]Test loss: 0.27322547830924204\n",
      "\n",
      "new best accuracy: 0.9142\n",
      "\n",
      "EPOCH: 14\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 208.89it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 456.98it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 204.45it/s]Test loss: 0.27100597388004954\n",
      "\n",
      "new best accuracy: 0.9173\n",
      "\n",
      "EPOCH: 15\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 211.80it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 451.31it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 202.49it/s]Test loss: 0.27028174057037013\n",
      "\n",
      "new best accuracy: 0.9181\n",
      "\n",
      "EPOCH: 16\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 214.34it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 461.51it/s]\n",
      "Training:   6%|▌         | 18/313 [00:00<00:01, 174.06it/s]Test loss: 0.2661225247326531\n",
      "\n",
      "new best accuracy: 0.9182\n",
      "\n",
      "EPOCH: 17\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 196.11it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 437.81it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 195.28it/s]Test loss: 0.26696329629873927\n",
      "\n",
      "new best accuracy: 0.9193\n",
      "\n",
      "EPOCH: 18\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 209.25it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 441.92it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 192.67it/s]Test loss: 0.2714996355809743\n",
      "\n",
      "new best accuracy: 0.9200\n",
      "\n",
      "EPOCH: 19\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 211.65it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 460.88it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 204.07it/s]Test loss: 0.2650552207156073\n",
      "\n",
      "EPOCH: 20\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 203.96it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 410.95it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 199.45it/s]Test loss: 0.2684008148086222\n",
      "\n",
      "EPOCH: 21\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 209.64it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 443.81it/s]\n",
      "Training:   6%|▌         | 19/313 [00:00<00:01, 187.15it/s]Test loss: 0.26828251958270616\n",
      "\n",
      "EPOCH: 22\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 212.61it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 403.71it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 198.33it/s]Test loss: 0.264073519130485\n",
      "\n",
      "EPOCH: 23\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 214.55it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 425.12it/s]\n",
      "Training:   5%|▌         | 16/313 [00:00<00:01, 156.03it/s]Test loss: 0.26884951395324513\n",
      "\n",
      "EPOCH: 24\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 210.90it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 449.32it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 202.65it/s]Test loss: 0.2666035871716994\n",
      "\n",
      "EPOCH: 25\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 215.93it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 447.98it/s]\n",
      "Training:   7%|▋         | 21/313 [00:00<00:01, 202.75it/s]Test loss: 0.27013712621565106\n",
      "\n",
      "EPOCH: 26\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 215.28it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 428.74it/s]\n",
      "Training:   7%|▋         | 22/313 [00:00<00:01, 212.57it/s]Test loss: 0.26469933675437035\n",
      "\n",
      "EPOCH: 27\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 210.38it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 459.02it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 193.37it/s]Test loss: 0.26835664625786526\n",
      "\n",
      "EPOCH: 28\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 212.71it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 425.83it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 193.34it/s]Test loss: 0.26592961425268197\n",
      "\n",
      "EPOCH: 29\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 212.99it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 454.53it/s]\n",
      "Training:   6%|▋         | 20/313 [00:00<00:01, 194.65it/s]Test loss: 0.2687177338366267\n",
      "\n",
      "EPOCH: 30\n",
      "Training: 100%|██████████| 313/313 [00:01<00:00, 211.81it/s]\n",
      "Testing: 100%|██████████| 79/79 [00:00<00:00, 423.42it/s]Test loss: 0.26465109377344953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = DrawingsDataset(mtype=\"train\")\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=MODEL_CFG['batch_size'], shuffle=True)\n",
    "\n",
    "test_data = DrawingsDataset(mtype=\"test\")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=MODEL_CFG['batch_size'], shuffle=True)\n",
    "\n",
    "print(\"Train images: %d\" % len(train_data))\n",
    "print(\"Test images: %d\" % len(test_data))\n",
    "\n",
    "net = Net().cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=MODEL_CFG[\"learning_rate\"], momentum=MODEL_CFG['momentum'],\n",
    "                            weight_decay=MODEL_CFG['weight_decay'])\n",
    "\n",
    "train_accuracy = 0.0\n",
    "test_accuracy = 0.0\n",
    "best_accuracy = 0.0\n",
    "    \n",
    "def train():\n",
    "    net.train()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    data_loader = tqdm(train_loader, desc='Training')\n",
    "    for batch_idx, (drawings, labels) in enumerate(data_loader):\n",
    "        drawings, labels = torch.autograd.Variable(drawings.cuda()), torch.autograd.Variable(labels.cuda())\n",
    "        drawings = drawings.view(-1, 1, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        drawings /= 255.0\n",
    "\n",
    "        # forward\n",
    "        output = net(drawings)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accuracy\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += float(pred.eq(labels.data).sum())\n",
    "\n",
    "        # exp moving average\n",
    "        loss_avg = loss_avg*0.2+float(loss)*0.8\n",
    "\n",
    "    global train_accuracy\n",
    "    train_accuracy = correct/len(train_loader.dataset)\n",
    "\n",
    "def test():\n",
    "    net.eval()\n",
    "    loss_avg = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    data_loader = tqdm(test_loader, desc='Testing')\n",
    "    for batch_idx, (drawings, labels) in enumerate(data_loader):\n",
    "        drawings, labels = torch.autograd.Variable(drawings.cuda()), torch.autograd.Variable(labels.cuda())\n",
    "        \n",
    "        drawings = drawings.view(-1, 1, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        drawings /= 255.0\n",
    "\n",
    "        # forward\n",
    "        output = net(drawings)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # accuracy\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += float(pred.eq(labels.data).sum())\n",
    "\n",
    "        # test loss average\n",
    "        loss_avg += float(loss)\n",
    "\n",
    "    print(f'Test loss: {loss_avg/len(test_loader)}')\n",
    "    \n",
    "    global test_accuracy\n",
    "    test_accuracy = correct/len(test_loader.dataset)\n",
    "    \n",
    "for epoch in range(MODEL_CFG['epochs']):\n",
    "    print(\"\\nEPOCH: \"+str(epoch+1))\n",
    "    \n",
    "    if epoch+1 in MODEL_CFG['lr_decay_step']:\n",
    "        MODEL_CFG['learning_rate'] *= MODEL_CFG['gamma']\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = MODEL_CFG['learning_rate']\n",
    "            \n",
    "    train()\n",
    "    test()\n",
    "    \n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(net.state_dict(), os.path.join(MODELS_DIR, 'model.pth'))\n",
    "        print(\"\\nnew best accuracy: %.4f\" % best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "89b42bf818aba7caf36f808f4e4d121a5375763d533b39721a76e70b1f011c6b"
   }
  },
  "interpreter": {
   "hash": "89b42bf818aba7caf36f808f4e4d121a5375763d533b39721a76e70b1f011c6b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}